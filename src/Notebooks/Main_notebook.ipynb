{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBO0z0Q4Vig0"
   },
   "source": [
    "# Main notebook \n",
    "## used to train different model parameters and using different losses on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "from smooth_tiled_predictions import cheap_tiling_prediction\n",
    "\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "directoryOfProject = 'drive/MyDrive/Project2ML/'\n",
    "\n",
    "data_dir = directoryOfProject + 'trainingWithGenerator/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/'\n",
    "\n",
    "test_dir = directoryOfProject + 'test/'\n",
    "test_dir_image = test_dir + 'images/test_'\n",
    "test_dir_groundtruth = test_dir + 'groundtruth/test_'\n",
    "\n",
    "originalDataImage = directoryOfProject + 'training/' + 'images/'\n",
    "originalDataGrountruth = directoryOfProject + 'training/' + 'groundtruth/'\n",
    "\n",
    "IMAGE_OPEN = os.listdir(train_data_filename)\n",
    "\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "PIXEL_DEPTH = 255\n",
    "SEED = 66478\n",
    "IMG_WIDTH    = 400\n",
    "IMG_HEIGHT   = 400\n",
    "\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "NUMBER_OF_EXTRA_IMAGES_PER_IMAGE = 40\n",
    "\n",
    "NUMBER_OF_FILE_TO_SEARSH_TRESHOLD = 200\n",
    "\n",
    "VALIDATIONSPLIT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "NEED_TO_GENERATE_NEW_IMAGES = False #If the new images created from the 100 given images don't exist\n",
    "COMPRESSED_IMAGE_EXIST = False #If you have loaded the images before\n",
    "PREDICTION_IMAGE_EXIST = False #If you have created/loaded the prediction using the model \n",
    "\n",
    "BINARY_AND_JACCARD = False\n",
    "BINARY_AND_DICE = False\n",
    "BINARY_CROSS_ENTROPY = True\n",
    "\n",
    "NEED_TO_CREATE_MODEL = False #If the model hasn't been trained/Created before\n",
    "\n",
    "\n",
    "\n",
    "foreground_threshold = 0.51 #Value of the threshold for the AICrown submission\n",
    "\n",
    "if (BINARY_AND_JACCARD):\n",
    "  extraDirectory = 'jaccard'\n",
    "if (BINARY_AND_DICE):\n",
    "  extraDirectory = 'dice'\n",
    "if (BINARY_CROSS_ENTROPY):\n",
    "  extraDirectory = 'binnary'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images to augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFFPKctFK-KE"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_images(save_to, imgs_number):\n",
    "    '''\n",
    "    Image generating function, it will save generated images in a given folder.\n",
    "    :param save_to: folder name where to save the images\n",
    "    :param n: number of images generated per source image ( n= 10 will result in 100*10=1000 images)\n",
    "    '''\n",
    "\n",
    "    source_images = os.listdir(train_data_path)\n",
    "    source_groundtruth = os.listdir(train_labels_path)\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    if not path.exists('../data/{}'.format(save_to)):\n",
    "        os.mkdir('../data/{}'.format(save_to))\n",
    "    if not path.exists('../data/{}/images'.format(save_to)):\n",
    "        os.mkdir('../data/{}/images'.format(save_to))\n",
    "    else:\n",
    "        if (len(os.listdir('../data/{}/images'.format(save_to)))==100*imgs_number):\n",
    "            print(\"Existing images found!\")\n",
    "            return 0\n",
    "\n",
    "    if not path.exists('../data/{}/labels'.format(save_to)):\n",
    "        os.mkdir('../data/{}/labels'.format(save_to))\n",
    "    new_img_folder = '../data/{}/images'.format(save_to)\n",
    "    new_gt_folder = '../data/{}/labels'.format(save_to)\n",
    "\n",
    "    for n, id_ in tqdm(enumerate(source_images), total=len(source_images)):\n",
    "        img = imread(train_data_path + id_ )[:,:,:IMG_CHANNELS]\n",
    "        img = resize(img, (IMG_SIZE, IMG_SIZE), mode='constant', preserve_range=True)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        mask = np.zeros((IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)\n",
    "        mask_ = imread(train_labels_path + id_)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_SIZE, IMG_SIZE), mode='constant',\n",
    "                                            preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "\n",
    "        # This is the image data genenator where you can tweak the parameters\n",
    "        datagen = ImageDataGenerator(\n",
    "        rotation_range=360,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.6,\n",
    "        fill_mode=\"reflect\",\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        )\n",
    "        imageGenerated = datagen.flow(\n",
    "        img,\n",
    "        y=mask,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "        save_to_dir=new_img_folder,\n",
    "        save_prefix=str(n) ,\n",
    "        save_format=\"png\",\n",
    "        )\n",
    "        groundTruthGenerated = datagen.flow(\n",
    "        mask,\n",
    "        y=mask,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "        save_to_dir=new_gt_folder,\n",
    "        save_prefix= str(n),\n",
    "        save_format=\"png\",\n",
    "        )\n",
    "        totalgenerated=0\n",
    "\n",
    "        for image in imageGenerated:\n",
    "            totalgenerated+=1\n",
    "            if (totalgenerated >= imgs_number):\n",
    "                totalgenerated=0\n",
    "                break \n",
    "\n",
    "        for image in groundTruthGenerated:   \n",
    "            totalgenerated+=1\n",
    "            if (totalgenerated >= imgs_number):\n",
    "                totalgenerated=0\n",
    "                break \n",
    "                \n",
    "                \n",
    "if (NEED_TO_GENERATE_NEW_IMAGES):\n",
    "    IMAGE_OPEN_original = os.listdir(originalDataImage)\n",
    "    generate_images(train_data_filename, NUMBER_OF_EXTRA_IMAGES_PER_IMAGE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBRLJ5T0hSJ4"
   },
   "outputs": [],
   "source": [
    "# This part is to load the already existing images with their groundtruth. \n",
    "# If it is already done, you can load the compressed version. \n",
    "\n",
    "X = np.zeros((len(IMAGE_OPEN), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y = np.zeros((len(IMAGE_OPEN), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "if (COMPRESSED_IMAGE_EXIST == False):\n",
    "  for n, id_ in tqdm(enumerate(IMAGE_OPEN), total=len(IMAGE_OPEN)):\n",
    "      path = data_dir\n",
    "      img = imread(train_data_filename + id_ )[:,:,:IMG_CHANNELS]\n",
    "      img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "      X[n] = img\n",
    "      mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "      mask_ = imread(train_labels_filename + id_)\n",
    "      mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
    "                                        preserve_range=True), axis=-1)\n",
    "      mask = np.maximum(mask, mask_)\n",
    "      Y[n] = mask\n",
    "  x_train=X\n",
    "  y_train=Y\n",
    "  savez_compressed(data_dir +'/X.npz', x_train)\n",
    "  savez_compressed(data_dir +'/Y.npz', y_train)\n",
    "else:\n",
    "  x_train = np.load(data_dir +'/X.npz')['arr_0']\n",
    "  y_train = np.load(data_dir +'/Y.npz')['arr_0']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2Jy0Xet8mD1"
   },
   "outputs": [],
   "source": [
    "def jaccard_loss(y_true, y_pred,  smooth=1):\n",
    "    '''\n",
    "    jaccard loss function\n",
    "    :param y_true: true labels \n",
    "    :param y_pred: predicted labels\n",
    "    :return: computed loss\n",
    "    '''\n",
    "    y_true_int = tf.where(y_true==True, 1., 0.)\n",
    "    y_true_f = tf.keras.backend.flatten(y_true_int)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    jaccard = (intersection +  smooth) / (tf.keras.backend.sum(y_true_f)   +  tf.keras.backend.sum(y_pred_f) - intersection + smooth)\n",
    "\n",
    "    return 1-jaccard\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth = 1):\n",
    "    '''\n",
    "    dice loss function\n",
    "    :param y_true: true labels \n",
    "    :param y_pred: predicted labels\n",
    "    :return: computed loss\n",
    "    '''\n",
    "    y_true_int = tf.where(y_true==True, 1., 0.)\n",
    "    y_true_f = tf.keras.backend.flatten(y_true_int)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f)   +  tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "    return 1-dice\n",
    "\n",
    "def jaccard_and_binary_crossentropy(y_true, y_pred):\n",
    "    '''\n",
    "    jaccard and binary crossentropy loss function\n",
    "    :param y_true: true labels \n",
    "    :param y_pred: predicted labels\n",
    "    :return: computed loss\n",
    "    '''\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred) + jaccard_loss(y_true, y_pred)\n",
    "\n",
    "def dice_and_binary_crossentropy(y_true, y_pred):\n",
    "    '''\n",
    "    dice and binary crossentropy loss function\n",
    "    :param y_true: true labels \n",
    "    :param y_pred: predicted labels\n",
    "    :return: computed loss\n",
    "    '''\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aUdHian8L59"
   },
   "outputs": [],
   "source": [
    "#We pick the loss we want\n",
    "if (BINARY_CROSS_ENTROPY):\n",
    "  loss_loaded = tf.keras.losses.binary_crossentropy\n",
    "else if (BINARY_AND_DICE):\n",
    "  loss_loaded = dice_and_binary_crossentropy\n",
    "else if (BINARY_AND_JACCARD):\n",
    "  loss_loaded = jaccard_and_binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-score metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBbOY_9sEXNw"
   },
   "outputs": [],
   "source": [
    "#We define here our F1 method\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    '''\n",
    "    computes the recall\n",
    "    source: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "    :param y_true: real label\n",
    "    :param y_pred: prediction\n",
    "    :return recall: the computed recall\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    '''\n",
    "    computes the precision\n",
    "    source: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "    :param y_true: real label\n",
    "    :param y_pred: prediction\n",
    "    :return recall: the computed precision\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    '''\n",
    "    computes the F1_score\n",
    "    source: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "    :param y_true: real label\n",
    "    :param y_pred: prediction\n",
    "    :return : the computed f1_score\n",
    "    '''\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0zqElZZb4Mi"
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "conv1 = BatchNormalization() (conv1)\n",
    "conv1 = Dropout(0.1) (conv1)\n",
    "conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1)\n",
    "conv1 = BatchNormalization() (conv1)\n",
    "pooling1 = MaxPooling2D((2, 2)) (conv1)\n",
    "\n",
    "conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling1)\n",
    "conv2 = BatchNormalization() (conv2)\n",
    "conv2 = Dropout(0.1) (conv2)\n",
    "conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2)\n",
    "conv2 = BatchNormalization() (conv2)\n",
    "pooling2 = MaxPooling2D((2, 2)) (conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling2)\n",
    "conv3 = BatchNormalization() (conv3)\n",
    "conv3 = Dropout(0.2) (conv3)\n",
    "conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3)\n",
    "conv3 = BatchNormalization() (conv3)\n",
    "pooling3 = MaxPooling2D((2, 2)) (conv3)\n",
    "\n",
    "conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling3)\n",
    "conv4 = BatchNormalization() (conv4)\n",
    "conv4 = Dropout(0.2) (conv4)\n",
    "conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4)\n",
    "conv4 = BatchNormalization() (conv4)\n",
    "pooling4 = MaxPooling2D(pool_size=(2, 2)) (conv4)\n",
    "\n",
    "conv5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pooling4)\n",
    "conv5 = BatchNormalization() (conv5)\n",
    "conv5 = Dropout(0.3) (conv5)\n",
    "conv5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5)\n",
    "conv5 = BatchNormalization() (conv5)\n",
    "\n",
    "\n",
    "upsample6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (conv5)\n",
    "upsample6 = concatenate([upsample6, conv4])\n",
    "conv6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample6)\n",
    "conv6 = BatchNormalization() (conv6)\n",
    "conv6 = Dropout(0.2) (conv6)\n",
    "conv6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv6)\n",
    "conv6 = BatchNormalization() (conv6)\n",
    "\n",
    "upsample7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (conv6)\n",
    "upsample7 = concatenate([upsample7, conv3])\n",
    "conv7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample7)\n",
    "conv7 = BatchNormalization() (conv7)\n",
    "conv7 = Dropout(0.2) (conv7)\n",
    "conv7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv7)\n",
    "conv7 = BatchNormalization() (conv7)\n",
    "\n",
    "upsample8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (conv7)\n",
    "upsample8 = concatenate([upsample8, conv2])\n",
    "conv8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample8)\n",
    "conv8 = BatchNormalization() (conv8)\n",
    "conv8 = Dropout(0.1) (conv8)\n",
    "conv8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv8)\n",
    "conv8 = BatchNormalization() (conv8)\n",
    "\n",
    "upsample9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (conv8)\n",
    "upsample9 = concatenate([upsample9, conv1], axis=3)\n",
    "conv9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upsample9)\n",
    "conv9 = BatchNormalization() (conv9)\n",
    "conv9 = Dropout(0.1) (conv9)\n",
    "conv9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv9)\n",
    "conv9 = BatchNormalization() (conv9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv9)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss=loss_loaded, metrics=['accuracy', f1_m]) #We compile our model using the loss we previously loaded\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training or loading weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kucps-j6b6iJ"
   },
   "outputs": [],
   "source": [
    "#We create a model checkpoint to save our model\n",
    "#We can either load it, or create it if necessary\n",
    "checkpoint_path = data_dir + extraDirectory + \".ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "if (NEED_TO_CREATE_MODEL):\n",
    "  # Create checkpoint callback\n",
    "  cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                  save_weights_only=True,\n",
    "                                                  verbose=1)\n",
    "\n",
    "  callbacks = [\n",
    "    cp_callback \n",
    "  ]\n",
    "\n",
    "  results = model.fit(x_train, y_train, validation_split=VALIDATIONSPLIT, batch_size=BATCH_SIZE, epochs=EPOCHS,shuffle=True,\n",
    "                      callbacks=callbacks)\n",
    "else:\n",
    "  model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc-JNtLo3Zpg"
   },
   "outputs": [],
   "source": [
    "# We create here all the predictions using the model we just load/created and then compress\n",
    "# and save it in case of future needs.\n",
    "if (PREDICTION_IMAGE_EXIST):\n",
    "  predictions = np.load(data_dir +'predictions'+ extraDirectory +'.npz')['arr_0']\n",
    "else:\n",
    "  dir = data_dir + 'images'\n",
    "  list_ = os.listdir(dir) # dir is your directory path\n",
    "  toSave = []\n",
    "  for n, id_ in tqdm(enumerate(list_), total=len(list_)): \n",
    "    img = x_train[n]\n",
    "    img =np.expand_dims(img, axis=0)\n",
    "    predict = np.squeeze(model.predict(img, verbose=0))\n",
    "    toSave.append(predict)\n",
    "\n",
    "  predictions = toSave\n",
    "  savez_compressed(data_dir +'predictions'+ extraDirectory+ '.npz', toSave)\n",
    "  PREDICTION_IMAGE_EXIST = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO-eT0e5dMeR"
   },
   "outputs": [],
   "source": [
    "#We're here testing on an image to make sure our model works.\n",
    "\n",
    "idx = 12\n",
    "if (PREDICTION_IMAGE_EXIST):\n",
    "  predict = predictions[idx]\n",
    "else:   \n",
    "  x=np.array(x_train[idx])\n",
    "  x=np.expand_dims(x, axis=0)\n",
    "  predict = np.squeeze(model.predict(x, verbose = \"0\"))\n",
    "\n",
    "print(\"Prediction using our model :\")\n",
    "imshow(predict)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Value of the groundtruth\")\n",
    "imshow(np.squeeze(y_train[idx]))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image rotation and symmetry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM2V6xO0VsKV"
   },
   "outputs": [],
   "source": [
    "# This is an home made version to create rotations and fliped images. \n",
    "# For each image it will create 12 new others images, 4 rotations (0, 90, 180, and 270 degrees) \n",
    "# and 3 split (no split, split on X avis and split on Y axis)\n",
    "\n",
    "def create_rotations(filename):\n",
    "    '''\n",
    "    Creates 3 rotations of a given image and on its \n",
    "    corresponding groundtruth by 90 degrees \n",
    "    :param filename: path of the image to rotate\n",
    "    :return ouptput: list of the 8 images\n",
    "    '''\n",
    "    imageDirectory = originalDataImage + filename\n",
    "    groundtruthDirectory = originalDataGrountruth + filename\n",
    "    img = mpimg.imread(imageDirectory)\n",
    "    groundtruth = mpimg.imread(groundtruthDirectory)\n",
    "    imagesRotated = []\n",
    "    groundTruthRotated = []\n",
    "    output = []\n",
    "    for i in range(0,4):\n",
    "      imagesRotated.append(np.rot90(img,i))\n",
    "      groundTruthRotated.append(np.rot90(groundtruth,i))\n",
    "    output.append(imagesRotated)\n",
    "    output.append(groundTruthRotated)\n",
    "    return output\n",
    "\n",
    "def create_symmetry(image, groundtruth_):\n",
    "        '''\n",
    "    Creates 2 symmetries of a given image and on its corresponding\n",
    "    groundtruth on the x and y axis respectively \n",
    "    :param image: image to apply the symmetries on\n",
    "    :param groundtruth_: image corresponding groundtruth \n",
    "    :return ouptput: list of  the 6 images\n",
    "    '''\n",
    "    img = image\n",
    "    groundtruth = groundtruth_\n",
    "    imagesSymmetry = []\n",
    "    groundTruthSymmetry = []\n",
    "    output = []\n",
    "    imagesSymmetry.append(Image.fromarray((255.0 / img.max() * (img - img.min())).astype(np.uint8)))\n",
    "    imagesSymmetry.append(Image.fromarray(((255.0 / np.flip(img, 0).max() * (np.flip(img, 0) - np.flip(img, 0).min())).astype(np.uint8))))\n",
    "    imagesSymmetry.append(Image.fromarray((255.0 / np.flip(img, 1).max() * (np.flip(img, 1) - np.flip(img, 1).min())).astype(np.uint8)))\n",
    "\n",
    "    groundTruthSymmetry.append(Image.fromarray((255.0 / groundtruth.max() * (groundtruth - groundtruth.min())).astype(np.uint8)))\n",
    "    groundTruthSymmetry.append(Image.fromarray(((255.0 / np.flip(groundtruth, 0).max() * (np.flip(groundtruth, 0) - np.flip(groundtruth, 0).min())).astype(np.uint8))))\n",
    "    groundTruthSymmetry.append(Image.fromarray((255.0 / np.flip(groundtruth, 1).max() * (np.flip(groundtruth, 1) - np.flip(groundtruth, 1).min())).astype(np.uint8)))\n",
    "    output.append(imagesSymmetry)\n",
    "    output.append(groundTruthSymmetry)\n",
    "    return output\n",
    "\n",
    "if not os.path.isdir(train_data_filename):\n",
    "  os.mkdir(train_data_filename)\n",
    "if not os.path.isdir(train_labels_filename):\n",
    "  os.mkdir(train_labels_filename)\n",
    "for i in tqdm(range(1, 101)):\n",
    "        imageid = \"satImage_%.3d\" % i + '.png'\n",
    "        [rotationsImg, groundTruthImg] = create_rotations(imageid )\n",
    "        for k in range(0,4): \n",
    "          [symmetryImg, symmetryGroundTruth] = create_symmetry(rotationsImg[k],groundTruthImg[k])\n",
    "          for j in range(0,3):\n",
    "            imageidToSave = 'satImage_%4d' % ((i-1)*12+k*3+j) \n",
    "            symmetryImg[j].save(train_data_filename + imageidToSave + '.png')\n",
    "            symmetryGroundTruth[j].save(train_labels_filename + imageidToSave + '.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IQSu-nngqop"
   },
   "outputs": [],
   "source": [
    "#This part is to create a AICrown submission, the only parameter is the foreground_treshold\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename, index):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(index, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        index = 1\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn, index))\n",
    "            index+=1\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    submission_filename = data_dir + 'FinalResult.csv'\n",
    "    image_filenames = []\n",
    "    for i in tqdm(range(1, 51)):\n",
    "      x = imread(test_dir_image +  str(i) + '.png' )[:,:,:IMG_CHANNELS]\n",
    "      x_notsmooth = resize(x, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "      x_notsmooth=np.expand_dims(x_notsmooth, axis=0)\n",
    "      prediction_not_smooth = model.predict(x_notsmooth, verbose=0)\n",
    "      #We need to resize our image from (400,400) to (608,608)\n",
    "      prediction_not_smooth = resize(prediction_not_smooth[0], (IMG_HEIGHT+208, IMG_WIDTH+208), mode='constant', preserve_range=True) \n",
    "\n",
    "      #This is the prediction that is resized using the cheat_tilting_prediction, it happend that the resize function had better resultst than this one.\n",
    "      predictions_smooth = cheap_tiling_prediction(x, IMG_WIDTH, 1, pred_func=(\n",
    "          lambda img_batch_subdiv: model.predict(np.expand_dims(img_batch_subdiv, axis=0)[:,0,:,:])\n",
    "          )\n",
    "      )\n",
    "\n",
    "      image_filename = test_dir_groundtruth + '%.3d' % i + '.png'\n",
    "      mpimg.imsave( image_filename, np.squeeze(prediction_not_smooth))\n",
    "      image_filenames.append(image_filename)\n",
    "    masks_to_submission(submission_filename, *image_filenames)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwugNKeKgl4a"
   },
   "outputs": [],
   "source": [
    "#This part is made to find the best possible threshold value\n",
    "MIN_VALUE = 0.1\n",
    "MAX_VALUE = 0.9\n",
    "STEP = 0.05\n",
    "fg_array =  np.arange(MIN_VALUE,MAX_VALUE+STEP,STEP)\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "\n",
    "errorArray = []\n",
    "min = sys.float_info.max\n",
    "index = 0\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch, f):\n",
    "    df = np.mean(patch)\n",
    "    if df > f:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings_2(prediction, f):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    toReturn = np.zeros((prediction.shape[0], prediction.shape[1]))\n",
    "    patch_size = 16\n",
    "    for j in range(0, prediction.shape[1], patch_size):\n",
    "        for i in range(0, prediction.shape[0], patch_size):\n",
    "            patch = prediction[i:i + patch_size, j:j + patch_size]\n",
    "            toReturn[i:i + patch_size, j:j + patch_size] = patch_to_label(patch,f)\n",
    "    return toReturn\n",
    "\n",
    "image_filenames = []\n",
    "\n",
    "if  (PREDICTION_IMAGE_EXIST==False):\n",
    "  raise NameError('MAKE SURE TO FIRST CREATE THE PREDICTIONS USING THE MODEL OF THE IMAGES BEFORE TRYING TO FIND THE CORRECT THRESHOLD')  \n",
    "else:\n",
    "  for idx, f in tqdm(enumerate(fg_array), total= len(fg_array)):\n",
    "    error = 0\n",
    "    for i in (range(0, NUMBER_OF_FILE_TO_SEARSH+1)):\n",
    "      predict = predictions[i]\n",
    "\n",
    "      mask =  mask_to_submission_strings_2(predict,f)\n",
    "      error += np.abs(mask - np.squeeze(np.where(y_train[i]==True, 1, 0))).sum() #Computing the error between the groundtruth and the prediction with the labels\n",
    "    if (error<min):\n",
    "      min = error\n",
    "      index = idx\n",
    "    errorArray.append(error/NUMBER_OF_FILE_TO_SEARSH)  \n",
    "  plt.plot(fg_array, errorArray);\n",
    "  print(\"Threshold value is : \")\n",
    "  print(fg_array[index])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VersionCompleted.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
