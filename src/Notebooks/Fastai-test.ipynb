{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.ai tests.\n",
    "### This is the Notebook we used for some tests with this deep learning library.\n",
    "### Please note that in order to use it you need to generates augmented datasets in the Augment section\n",
    "\n",
    "<pre>\n",
    "To use this notebook you will need the additional following libraries:\n",
    "<strong>pip install fastai==1.0.58</strong>\n",
    "<strong>pip install path==15.0.1</strong>\n",
    "\n",
    "Inspiration for this notebook was found here:\n",
    "https://medium.com/analytics-vidhya/a-simple-cloud-detection-walk-through-using-convolutional-neural-network-cnn-and-u-net-and-bc745dda4b04\n",
    "\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.data import *\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from path import Path\n",
    "root_dir = \"../data/\"\n",
    "image_dir = root_dir + \"images/\"\n",
    "gt_dir = root_dir + \"groundtruth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE = 200\n",
    "\n",
    "if not path.exists('../data/cropped'):\n",
    "    os.mkdir('../data/cropped')\n",
    "if not path.exists('../data/cropped/croppedImages'):\n",
    "    os.mkdir('../data/cropped/croppedImages')\n",
    "if not path.exists('../data/cropped/croppedMasks'):\n",
    "    os.mkdir('../data/cropped/croppedMasks')\n",
    "    \n",
    "CROPPED_IMAGES_DIR = Path('../data/cropped/croppedImages')\n",
    "CROPPED_LABELS_DIR = Path('../data/cropped/croppedMasks')\n",
    "\n",
    "nbrOfImages = 100\n",
    "files = os.listdir(image_dir)\n",
    "files.remove('models')\n",
    "files.sort()\n",
    "imgtocrop = [load_image(image_dir + files[i]) for i in range(nbrOfImages)]\n",
    "gttocrop = [load_image(gt_dir + files[i]) for i in range(nbrOfImages)]\n",
    "\n",
    "for i in tqdm(range(nbrOfImages)):\n",
    "    a = img_crop(imgtocrop[i],CROP_SIZE,CROP_SIZE)\n",
    "    b = img_crop(gttocrop[i],CROP_SIZE,CROP_SIZE)\n",
    "\n",
    "    for j in range(len(a)):\n",
    "        Image.fromarray((255*a[j]).astype(np.uint8), 'RGB').save(\"../data/cropped/croppedImages\"+str(CROP_SIZE)+\"/satImage_\"+str(i)+\"_crop_\"+str(j)+\".png\")\n",
    "        Image.fromarray((np.where(b[j] > 0.5, 1, 0) * 255).astype(np.uint8),'L').save(\"../data/cropped/croppedMasks\"+str(CROP_SIZE)+\"/satImage_\"+str(i)+\"_crop_\"+str(j)+\".png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateImages = False\n",
    "\n",
    "import imageio\n",
    "import Augmentor\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "\n",
    "if not path.exists('../data/augmentedImages'):\n",
    "    os.mkdir('../data/augmentedImages')\n",
    "if not path.exists('../data/augmentedMasks'):\n",
    "    os.mkdir('../data/augmentedMasks')\n",
    "N_PATCHES = (400 // CROP_SIZE)**2 \n",
    "if generateImages:\n",
    "    for im in tqdm(range(100)):\n",
    "        for j in range(N_PATCHES):\n",
    "            image = imageio.imread('../data/cropped/croppedImages/satImage_{}_crop_{}.png'.format(i,j))\n",
    "            mask = imageio.imread('../data/cropped/croppedMasks/satImage_{}_crop_{}.png'.format(i,j))\n",
    "            # Initialize pipeline\n",
    "            p = Augmentor.DataPipeline([[np.array(image), np.array(mask)]])\n",
    "\n",
    "            # Apply augmentations\n",
    "            p.rotate(1, max_left_rotation=25, max_right_rotation=25)\n",
    "            p.flip_random(0.5)\n",
    "            p.rotate180(0.5)\n",
    "\n",
    "            # Sample from augmentation pipeline\n",
    "            images_aug = p.sample(100)\n",
    "\n",
    "            lis=[]\n",
    "            # Access augmented image and mask\n",
    "            augmented_image = images_aug[0][0]\n",
    "            augmented_mask = images_aug[0][1]\n",
    "            for k in range(len(images_aug)):\n",
    "                augmented_image = images_aug[k][0]\n",
    "                augmented_mask = images_aug[k][1]\n",
    "                Image.fromarray((augmented_image).astype(np.uint8),'RGB').save(\"../data/cropped/croppedImages/satImage_{}_crop_{}.png\".format(i,N_PATCHES+k))\n",
    "                Image.fromarray((augmented_mask).astype(np.uint8),'L').save(\"../data/cropped/croppedMasks/satImage_{}_crop_{}.png\".format(i,N_PATCHES+k))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "\n",
    "def get_lbl_fn(img_fn: path):  \n",
    "  \n",
    "    img_name = img_fn.name\n",
    "    lbl_name = img_name\n",
    "\n",
    "    return img_fn.parent.parent/('augmentedMasks/' + lbl_name)\n",
    "\n",
    "\n",
    "img_names = get_image_files(CROPPED_IMAGES_DIR)\n",
    "lbl_names = get_image_files(CROPPED_LABELS_DIR)\n",
    "\n",
    "print(len(img_names), len(lbl_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for segmentation with 0,255 labels:\n",
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return open_mask(fn, div=True)\n",
    "class SegItemListCustom(SegmentationItemList):\n",
    "    _label_cls = SegLabelListCustom\n",
    "\n",
    "bs = 2\n",
    "\n",
    "# to test smaller patches, please enter different patch shape and modify the images and labels directories\n",
    "# with the ones containing your cropped images.\n",
    "\n",
    "patch_shape = CROP_SIZE\n",
    "\n",
    "print(f'Batch size:{bs}')\n",
    "print(f'Patch shape:{patch_shape}')\n",
    "\n",
    "src = (SegItemListCustom.from_folder(\n",
    "    path_img).split_by_rand_pct().label_from_func(\n",
    "        lambda x: path_lbl / x.relative_to(path_img), classes=['rest',\n",
    "                                                              'road']))\n",
    "\n",
    "data = (src.transform( size=patch_shape, tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def acc_metric(input, target):\n",
    "    '''\n",
    "    accuracy metric function\n",
    "    '''\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "# weight decay\n",
    "wd = 1e-2\n",
    "#learning rate\n",
    "lr=1e-3\n",
    "\n",
    "learn = unet_learner(data, models.resnet34, metrics=acc_metric, wd=wd)\n",
    "learn.fit_one_cycle(12, lr)\n",
    "learn.save(\"Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one image from the validation dataset\n",
    "img = learn.data.valid_ds.x[86]\n",
    "mask = learn.data.valid_ds.y[86]\n",
    "pred = learn.predict(img)[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])\n",
    "pred.show(ax[2])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_mask(cropped_masks,size):\n",
    "    '''\n",
    "    reassemble a nparray of mask to an Image\n",
    "    :param cropped_masks: nparray of shape(625,16,16) containing all cropped 16x16 masks\n",
    "    :return out: nparray of shape(400,400)\n",
    "    '''\n",
    "    w = size // 32\n",
    "    print(\"w\", w)\n",
    "    h = size // w\n",
    "    out = np.zeros((size, size))\n",
    "    for i in range(w):\n",
    "        columns = np.concatenate(cropped_masks[0 + i * w:w + i * w], axis=0)\n",
    "        out[:, 0 + i * h:h + i * h] = columns\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage(img_path: Path, out_folder: Path):\n",
    "    '''\n",
    "    Predict the mask of an image and save the result in the wanted folder\n",
    "    :param img: path to the image to predict\n",
    "    :param out_folder: Path in which the image will be saved\n",
    "    '''\n",
    "    \n",
    "    img = load_image(img_path)\n",
    "    size = img.shape[1]\n",
    "    print(size,\"size\")\n",
    "    pred = []\n",
    "    cropped = img_crop(img,CROP_SIZE,CROP_SIZE)\n",
    "    imgss = []\n",
    "    numberOfPatches = (size//CROP_SIZE)**2\n",
    "    for i in range(len(cropped)):\n",
    "        Image.fromarray((cropped[i] * 255).astype(np.uint8),'RGB').save(\"../data/croppedPredictions/satImage_\"+str(i)+\"_crop\"+\".png\")   \n",
    "    for i in range(numberOfPatches):\n",
    "        im = open_image(\"../data/croppedPredictions/satImage_\"+str(i)+\"_crop.png\")\n",
    "        pred.append(learn.predict(im)[0])\n",
    "        predmask = np.array([np.array(i.data) for i in pred])\n",
    "    predmask = predmask.reshape((numberOfPatches,CROP_SIZE,CROP_SIZE))\n",
    "    img = concatenate_mask(predmask, size)\n",
    "    if not (out_folder / img_path.name.replace(\".png\",\"_prediction.png\")).exists():\n",
    "        try:\n",
    "            (out_folder).mkdir()\n",
    "        except:\n",
    "            print(\"file exist\")\n",
    "    out = Image.fromarray((img * 255).astype(np.uint8),'L').save(out_folder / img_path.name.replace(\".png\",\"_prediction.png\"))   \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "from skimage.transform import resize\n",
    "\n",
    "foreground_threshold = 0.5 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    print(df)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    submission_filename = '../submissions/sub8.csv'\n",
    "    image_filenames = []\n",
    "    for i in tqdm(range(1, 51)):\n",
    "        x = open_image('../data/test/test_set_images/test_resized' +  str(i) + '.png' )\n",
    "        predict = learn.predict(x)[0]\n",
    "        image_filename = '../data/test/test_set_prediction/test_' + str(i) + '.png'\n",
    "        \n",
    "        predict.save(image_filename)\n",
    "        r = mpimg.imread(image_filename)\n",
    "        x = 255*resize(255*r, (608, 608), mode='constant', preserve_range=True)\n",
    "        Image.fromarray((x).astype(np.uint8), 'L').save(image_filename)\n",
    "\n",
    "        image_filenames.append(image_filename)\n",
    "    masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
